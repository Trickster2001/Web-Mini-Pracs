import csv
from kora.selenium import wd
from bs4 import BeautifulSoup
from selenium import webdriver

def get_url(search_term):
    template = "https://www.nike.com/in/w?q=shoes&vst={}"
    search_term = search_term.replace(' ','%20')
    return template.format(search_term)

options = webdriver.ChromeOptions()
options.add_argument('-headless')
options.add_argument('-no-sandbox')
options.add_argument('-disable-dev-shm-usage')
driver_path = 'E:/chromedriver' # update this with the path to your Chrome driver executable
wd = webdriver.Chrome(executable_path=driver_path, options=options)
wd.get(get_url('shoes')) # search for running shoes on Nike

soup = BeautifulSoup(wd.page_source, 'html.parser')

results = soup.find_all('div',{'class':'product-card__body'}) # find Nike-specific div tags that contain product information
print(len(results))

def extract_record(item):
    name = item.find('a', {'class': 'product-card__link-overlay'}).text
    price = item.find('div', {'class': 'product-price__wrapper'}).text
    return (name, price)

records = []
for item in results:
    records.append(extract_record(item))

for record in records:
    print(record)